## Journals in which the paper can be published:
1. ACM transaction on computing education(1.3)
2. Computer application in engg. education(1.4)
3. Computer and Education(5.6)
4. IEEE transaction on education(2.27)
5. International journal of engg. education(0.66)
6. Internation journal of technology and design education(1.3)
7. Journal of engineering education(1.5)
8. Journal of science education and technology(1.78)
9. Active Learning in higher education (2.29)

## Ontolgy in which papers:

# Paper1 : https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.92.4964&rep=rep1&type=pdf
(ACM Journal of Education Resources in Computing)
1. This paper basically desighns the concept map just like us , but has better relationships between
the concepts:
Namely the relations defined are only of certain types:

1. Is a Property of 
2. Is Associated with 
3. Is composed of

--> mainly subclass , superclass .

Basically , they have desighned a model of how any concept can be visualized in terms of graph.This is called a T model.
So they classify all the information into different T models connected to each other.
Since it is is a defined model it enables them to do automated reasoning.
Also they are able to process many logical arguments.


##Paper2 :https://link.springer.com/chapter/10.1007/978-3-642-32600-4_13
(International Conference on Database and Expert Systems Application)
Their methodolgy
1. 1st they use a power point reader to extract the notes in power point slides.
2. They then do concept extraction after getting the text from the power point slides.
  >Pre-processing : removing stop words , removing white spaces
  >Tagging : POS Tagging and Lemmatizing
  >They take out the nouns and the compound nouns from the processed text and use the term frequency in the document to rank the concepts
  
3. They then perform the n gram count and then indentify the location of the concepts.
4.(Special Step) Since in powerpoint one highlights certain text according to their importance level, thus they use a probability model to say ,
what terms have good weights.

Concept Hierarchy Extraction : Here they differ from us by huge margin, whereas we use a wikidata corpus to decide hierarchy, they have used the
power point presentation to do variuos types of analysis from the powerpoint slides.

#My analysis : Both the papers devide the task of ontology extraction into concept extraction anf then Concept hierarchy formation.
#We have done it also like that although methods of both differ from our method.

I will also give a read to this paper which uses ontology using Deep Learning:https://link.springer.com/chapter/10.1007/978-3-030-35445-9_50

